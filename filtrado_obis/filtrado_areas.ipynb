{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "139cd00d",
   "metadata": {},
   "source": [
    "The main objective of this notebook is to create a .csv file where there are the samples ('muestra' in spanish), number of observations on each sample, area, date, position and depth of each observation. The dataset is different for each filum and there are 3 filum, that are crustacea, cnidaria and mollusca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a48e9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the libraries\n",
    "\n",
    "import pandas\n",
    "import geopandas as gpd\n",
    "import os \n",
    "import fiona"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83be4ca",
   "metadata": {},
   "source": [
    "We start this mission by loading the different areas that separate the shelf zone of the world. This is an archive with 66 zones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c77d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shapefile = gpd.read_file(r'C:\\Users\\glode\\OneDrive\\Desktop\\doctorado\\filtrado_obis\\lme66.shp')#shapefile.Reader(r'C:\\Users\\glode\\OneDrive\\Desktop\\doctorado\\programa\\lme66.shp')\n",
    "\n",
    "# Ver los registros\n",
    "shapefile = shapefile.set_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b5eb65",
   "metadata": {},
   "source": [
    "We charge the data of the different datasets, the data is downloaded in OBIS and it is filtered using the Filtrado_OBIS_F1.py. Now we have data with the parameters: latitude, longitude, depth, genusid (this parameters is a Worms index that indicates the genera of each observation), date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a5e6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['decimalLatitude', 'decimalLongitude', 'depth', 'genusid',\n",
      "       'fecha_hora'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#We charge the data\n",
    "\n",
    "data=pandas.read_csv('Occurrence_Filtrado_F1_mollusca_sinprofundidad.txt', sep='\\t')\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41edb237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is done to check how much data have genusid\n",
    "\n",
    "data_genusid=data[data['genusid'].notna()]\n",
    "\n",
    "print(len(data))    \n",
    "print(len(data_genusid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b8486a",
   "metadata": {},
   "source": [
    "We create a new column to clean the date_hour column, it contains the hour but we don't need that. Furthermore, we convert the column to a dataset and we overwrite the date column with this information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9984b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the data\n",
    "data['fecha_hora_limpia'] = data['fecha_hora'].str.extract(r'^(\\d{2}-\\d{2}-\\d{4})')[0]\n",
    "\n",
    "#Convert to datetime\n",
    "data['fecha_hora_limpia'] = pandas.to_datetime(data['fecha_hora_limpia'], format='%d-%m-%Y')\n",
    "\n",
    "#Overwrite the original column\n",
    "data[\"fecha_hora\"]=data[\"fecha_hora_limpia\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042dea09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decimalLatitude</th>\n",
       "      <th>decimalLongitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>genusid</th>\n",
       "      <th>fecha_hora</th>\n",
       "      <th>fecha_hora_limpia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-39.478333</td>\n",
       "      <td>177.005000</td>\n",
       "      <td>12.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1976-09-04</td>\n",
       "      <td>1976-09-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-39.466667</td>\n",
       "      <td>177.136667</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1976-09-04</td>\n",
       "      <td>1976-09-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-39.583333</td>\n",
       "      <td>177.071667</td>\n",
       "      <td>7.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1976-09-05</td>\n",
       "      <td>1976-09-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-39.516667</td>\n",
       "      <td>177.416667</td>\n",
       "      <td>49.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1976-09-05</td>\n",
       "      <td>1976-09-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-39.400000</td>\n",
       "      <td>177.666667</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1976-09-05</td>\n",
       "      <td>1976-09-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   decimalLatitude  decimalLongitude  depth  genusid fecha_hora  \\\n",
       "0       -39.478333        177.005000   12.5      NaN 1976-09-04   \n",
       "1       -39.466667        177.136667   15.0      NaN 1976-09-04   \n",
       "2       -39.583333        177.071667    7.5      NaN 1976-09-05   \n",
       "3       -39.516667        177.416667   49.0      NaN 1976-09-05   \n",
       "4       -39.400000        177.666667   33.0      NaN 1976-09-05   \n",
       "\n",
       "  fecha_hora_limpia  \n",
       "0        1976-09-04  \n",
       "1        1976-09-04  \n",
       "2        1976-09-05  \n",
       "3        1976-09-05  \n",
       "4        1976-09-05  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To check if we have done it correctly\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8841ad1",
   "metadata": {},
   "source": [
    "We just select the points that are not nan in the genusid column, i.e., the points that have information about the genera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916bb84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_genusid=data[data['genusid'].notna()]\n",
    "print(data_genusid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1a6746",
   "metadata": {},
   "source": [
    "We create the 'muestra' column. There are the same 'muestra' the points that have the same latitude, longitude and date. We assign to each of this group a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25548f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\glode\\AppData\\Local\\Temp\\ipykernel_7696\\4132720530.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_genusid['muestra'] = data_genusid.groupby(['decimalLatitude', 'decimalLongitude', 'fecha_hora']).ngroup()\n"
     ]
    }
   ],
   "source": [
    "#Create the 'muestra' column\n",
    "data_genusid['muestra'] = data_genusid.groupby(['decimalLatitude', 'decimalLongitude', 'fecha_hora']).ngroup()\n",
    "#Check if the column was created correctly\n",
    "print(data_genusid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f2670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We order the data by 'muestra' to facilitate the testing\n",
    "df_ordenado = data_genusid.sort_values(by='muestra')\n",
    "print(df_ordenado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70172e8e",
   "metadata": {},
   "source": [
    "Once we have created the sample column, we have to create the column 'observaciones'. This column describes the number of observations, that here is considered as one row, that has each 'muestra'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a4bbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\glode\\AppData\\Local\\Temp\\ipykernel_7696\\3624596633.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_genusid['observaciones'] = data_genusid.groupby('muestra')['muestra'].transform('count')\n"
     ]
    }
   ],
   "source": [
    "#Create the column 'observaciones'\n",
    "data_genusid['observaciones'] = data_genusid.groupby('muestra')['muestra'].transform('count')\n",
    "#We order the data by 'muestra' to facilitate the testing\n",
    "df_ordenado = data_genusid.sort_values(by='muestra')\n",
    "print(df_ordenado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad6a290",
   "metadata": {},
   "source": [
    "Now it's the time to identify the region where each point is located. For this purpose we create the points as an geodataframe and identify where each point is located using the function gpd.sjoin.  \n",
    "\n",
    "Furthermore, in the dataset there are points all around the globe, in ocean and even in land, and we don't need all of them. So we have to select only the points that corresponds to this region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59cfeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the data to a geodataframe\n",
    "gdf_puntos = gpd.GeoDataFrame(\n",
    "    data_genusid, \n",
    "    geometry=gpd.points_from_xy(data_genusid['decimalLongitude'], data_genusid['decimalLatitude']),\n",
    "    crs='EPSG:4326'\n",
    ")\n",
    "\n",
    "#We check the geography of the shapefile\n",
    "shapefile = shapefile.to_crs(epsg=4326)\n",
    "\n",
    "#We identify each point with the region of the shapefile\n",
    "gdf_resultado = gpd.sjoin(gdf_puntos, shapefile, how='left', predicate='within')\n",
    "\n",
    "#We check if we have done it correctly\n",
    "print(gdf_resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f61b1a",
   "metadata": {},
   "source": [
    "Doing this procedure we have obtained so many columns, and we don't need all of them, so we delete it.  \n",
    " Furthermore, there are points all around the globe, even in land areas, but we only have to consider the points that are inside any of these 66 regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe44fb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We delete the columns that we do not need\n",
    "\n",
    "df_resultado = gdf_resultado.drop(columns=['geometry', 'index_right', 'LME_NUMBER', 'LME_NAME', 'Shape_Area', 'Shape_Leng'])\n",
    "\n",
    "#We check if we have done it correctly, ordering the data by 'muestra' to facilitate the testing\n",
    "df_ordenado=df_resultado.sort_values(by='muestra')\n",
    "print(df_ordenado)\n",
    "\n",
    "#We select only the points that are inside a region\n",
    "df_ordenado=df_resultado[df_resultado['OBJECTID'].notna()]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9d1fa4",
   "metadata": {},
   "source": [
    "We save our progress in a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "6000a1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ordenado.to_csv('resultado_final_mollusca_sinprofundidad.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364990c8",
   "metadata": {},
   "source": [
    "We do this procedure for each filum, cnidaria, mollusca and crustacea"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
